{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"model.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Head\n",
      "                                               Review    Label\n",
      "0  may sound noisi initi find good place bar nois...  Postive\n",
      "1  good burger atmospher uniqu expect hard rock m...  Postive\n",
      "2  pre arrang breakfast peopl open us normal open...  Postive\n",
      "3  nice decor share platter crumb chicken spring ...  Postive\n",
      "4  great hard rock never bad countri favourit far...  Postive\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Head\\n\",data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Describe\n",
      "                                                    Review    Label\n",
      "count                                                3062     3062\n",
      "unique                                               1543        3\n",
      "top     visit son whilst break birthday price reason c...  Postive\n",
      "freq                                                    3     2742\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Describe\\n\", data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape\n",
      " (3062, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Shape\\n\",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Label Count\n",
      "\n",
      " Postive     2742\n",
      "Negative     173\n",
      "Neutral      147\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Label Count\\n\\n\", data[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data.Label)\n",
    "plt.title(\"LABEL\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(max_features = 3000)\n",
    "x = count_vect.fit_transform(data['Review']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3062, 2424)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: imblearn in c:\\users\\hp\\appdata\\roaming\\python\\python37\\site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: imbalanced-learn in c:\\users\\hp\\appdata\\roaming\\python\\python37\\site-packages (from imblearn) (0.7.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in c:\\users\\hp\\python\\python37\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\users\\hp\\python\\python37\\lib\\site-packages (from imbalanced-learn->imblearn) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.23 in c:\\users\\hp\\python\\python37\\lib\\site-packages (from imbalanced-learn->imblearn) (0.23.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\hp\\python\\python37\\lib\\site-packages (from imbalanced-learn->imblearn) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\hp\\python\\python37\\lib\\site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hp\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install --user -U imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_sample = SMOTE(random_state = 100, sampling_strategy = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_oversample,y_label = over_sample.fit_sample(x,data['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    2742\n",
       "Neutral     2742\n",
       "Postive     2742\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8226, 2424)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_oversample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### There is a data imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data_oversample,y_label, test_size = 0.3, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5758, 2424) (5758,)\n",
      "(2468, 2424) (2468,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['lime'] \n",
    "  \n",
    "plt.hist(y_train, \n",
    "         density = True,  \n",
    "         histtype ='barstacked', \n",
    "         color = colors)  \n",
    "  \n",
    "plt.title('balanced Data\\n\\n', \n",
    "          fontweight =\"bold\") \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble \n",
    "\n",
    "\n",
    "#### Random_Forest_bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,recall_score,classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=120, n_jobs=-1, random_state=50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators = 120,\n",
    "                           random_state = 50,\n",
    "                           n_jobs = -1,\n",
    "                           max_features = 'auto')\n",
    "RF.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = RF.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random forest classifier:\n",
      "\n",
      " 0.9809562398703403\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Random forest classifier:\\n\\n\", accuracy_score(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.98      0.97      0.97       804\n",
      "     Neutral       0.96      0.99      0.98       821\n",
      "     Postive       1.00      0.99      0.99       843\n",
      "\n",
      "    accuracy                           0.98      2468\n",
      "   macro avg       0.98      0.98      0.98      2468\n",
      "weighted avg       0.98      0.98      0.98      2468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\\n\", classification_report(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      "\n",
      " [[776  28   0]\n",
      " [  7 814   0]\n",
      " [  6   6 831]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix \\n\\n\", confusion_matrix(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiNomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn = MultinomialNB()\n",
    "mn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_pred = mn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial Naive Bayes\n",
      "\n",
      "\n",
      " 0.8379254457050244\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Multinomial Naive Bayes\\n\\n\\n\", accuracy_score(y_test,mn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report \n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.85      0.79       804\n",
      "     Neutral       0.85      0.71      0.78       821\n",
      "     Postive       0.93      0.95      0.94       843\n",
      "\n",
      "    accuracy                           0.84      2468\n",
      "   macro avg       0.84      0.84      0.84      2468\n",
      "weighted avg       0.84      0.84      0.84      2468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report \\n\\n\\n\", classification_report(y_test,mn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "\n",
      "\n",
      " [[682  81  41]\n",
      " [218 585  18]\n",
      " [ 20  22 801]]\n"
     ]
    }
   ],
   "source": [
    "print(\"confusion matrix:\\n\\n\\n\", confusion_matrix(y_test,mn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent \n",
    "\n",
    "\n",
    "##### Stochastic Gradient Descent (SGD) is a simple yet very efficient approach to fitting linear classifiers and regressors under convex loss functions such as (linear) Support Vector Machines and Logistic Regression. Even though SGD has been around in the machine learning community for a long time, it has received a considerable amount of attention just recently in the context of large-scale learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(alpha = 0.00047, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd.fit(x_train, y_train)\n",
    "sgd_pred = sgd.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SGD:\n",
      "\n",
      " 0.9448946515397083\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Accuracy of SGD:\\n\\n\", accuracy_score(y_test,sgd_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report of SGD\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.96      0.89      0.93       804\n",
      "     Neutral       0.89      0.97      0.93       821\n",
      "     Postive       0.99      0.97      0.98       843\n",
      "\n",
      "    accuracy                           0.94      2468\n",
      "   macro avg       0.95      0.94      0.94      2468\n",
      "weighted avg       0.95      0.94      0.95      2468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"classification report of SGD\\n\\n\", classification_report(y_test,sgd_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix sgd:\n",
      "\n",
      " [[716  84   4]\n",
      " [ 18 799   4]\n",
      " [ 10  16 817]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix sgd:\\n\\n\", confusion_matrix(y_test,sgd_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='ovr', random_state=42,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(solver = 'liblinear',\n",
    "                       multi_class = 'ovr',\n",
    "                       max_iter = 1000,\n",
    "                       random_state = 42,\n",
    "                       penalty =\"l2\")\n",
    "LR.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_pred = LR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression\n",
      "\n",
      " 0.9529983792544571\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Logistic Regression\\n\\n\", accuracy_score(y_test,LR_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of Logistic Regression\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.97      0.91      0.94       804\n",
      "     Neutral       0.90      0.98      0.94       821\n",
      "     Postive       1.00      0.97      0.98       843\n",
      "\n",
      "    accuracy                           0.95      2468\n",
      "   macro avg       0.95      0.95      0.95      2468\n",
      "weighted avg       0.96      0.95      0.95      2468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification of Logistic Regression\\n\\n\",classification_report(y_test,LR_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of Logistic Regression\n",
      "\n",
      "\n",
      " [[734  70   0]\n",
      " [ 16 801   4]\n",
      " [  8  18 817]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix of Logistic Regression\\n\\n\\n\",confusion_matrix(y_test,LR_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hp\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.3.1-py3-none-win_amd64.whl (95.2 MB)\n",
      "Requirement already satisfied, skipping upgrade: scipy in c:\\users\\hp\\python\\python37\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy in c:\\users\\hp\\python\\python37\\lib\\site-packages (from xgboost) (1.18.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.3.1\n"
     ]
    }
   ],
   "source": [
    "pip install --user -U xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import xgboost as xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xg.XGBClassifier(learning_rate = 0.01,\n",
    "                       colsample_bytree = 0.8,\n",
    "                       subsample = 0.8,\n",
    "                       objective = 'multi:softmax', \n",
    "                       n_estimators = 100, \n",
    "                       reg_alpha = 0.3,\n",
    "                       max_depth = 4, \n",
    "                       gamma = 1,\n",
    "                       num_class = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=1, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_class=3, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0.3,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=0.8,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGB = 0.784035656401945 \n",
      "\n",
      "Classification of XGB\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.89      0.58      0.70       804\n",
      "     Neutral       0.65      0.93      0.76       821\n",
      "     Postive       0.92      0.83      0.88       843\n",
      "\n",
      "    accuracy                           0.78      2468\n",
      "   macro avg       0.82      0.78      0.78      2468\n",
      "weighted avg       0.82      0.78      0.78      2468\n",
      " \n",
      "\n",
      "Confusion matrix of XGB\n",
      "\n",
      "\n",
      " [[469 321  14]\n",
      " [ 14 763  44]\n",
      " [ 45  95 703]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of XGB =\", accuracy_score(y_test,xgb_pred),\"\\n\")\n",
    "print(\"Classification of XGB\\n\\n\",classification_report(y_test,xgb_pred),\"\\n\")\n",
    "print(\"Confusion matrix of XGB\\n\\n\\n\",confusion_matrix(y_test,xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import  AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_model = OneVsRestClassifier(AdaBoostClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=AdaBoostClassifier())"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_pred = ada_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ada = 0.8642625607779578 \n",
      "\n",
      "Classification of ada\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.92      0.74      0.82       804\n",
      "     Neutral       0.77      0.93      0.84       821\n",
      "     Postive       0.94      0.92      0.93       843\n",
      "\n",
      "    accuracy                           0.86      2468\n",
      "   macro avg       0.87      0.86      0.86      2468\n",
      "weighted avg       0.87      0.86      0.86      2468\n",
      " \n",
      "\n",
      "Confusion matrix of ada\n",
      "\n",
      "\n",
      " [[592 189  23]\n",
      " [ 27 764  30]\n",
      " [ 25  41 777]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of ada =\", accuracy_score(y_test,ada_pred),\"\\n\")\n",
    "print(\"Classification of ada\\n\\n\",classification_report(y_test,ada_pred),\"\\n\")\n",
    "print(\"Confusion matrix of ada\\n\\n\\n\",confusion_matrix(y_test,ada_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:23:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:24:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:25:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, gamma=None,\n",
       "                                            gpu_id=None, importance_type='gain',\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr_model = OneVsRestClassifier(xg.XGBClassifier())\n",
    "ovr_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_model_pred = ovr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of OneVsRestClassifier using xgb= 0.9675850891410048 \n",
      "\n",
      "Classification of  OneVsRestClassifier using xgb\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.98      0.93      0.96       804\n",
      "     Neutral       0.93      0.99      0.96       821\n",
      "     Postive       1.00      0.98      0.99       843\n",
      "\n",
      "    accuracy                           0.97      2468\n",
      "   macro avg       0.97      0.97      0.97      2468\n",
      "weighted avg       0.97      0.97      0.97      2468\n",
      " \n",
      "\n",
      "Confusion matrix of  OneVsRestClassifier using xgb\n",
      "\n",
      "\n",
      " [[751  53   0]\n",
      " [  7 814   0]\n",
      " [  9  11 823]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of OneVsRestClassifier using xgb=\", accuracy_score(y_test,ovr_model_pred),\"\\n\")\n",
    "print(\"Classification of  OneVsRestClassifier using xgb\\n\\n\",classification_report(y_test,ovr_model_pred),\"\\n\")\n",
    "print(\"Confusion matrix of  OneVsRestClassifier using xgb\\n\\n\\n\",confusion_matrix(y_test,ovr_model_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# suport vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = svm.LinearSVC(multi_class = 'ovr')\n",
    "svm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred = svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of svm= 0.9647487844408428 \n",
      "\n",
      "Classification of  svm\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.95      0.96      0.96       804\n",
      "     Neutral       0.94      0.97      0.95       821\n",
      "     Postive       1.00      0.97      0.98       843\n",
      "\n",
      "    accuracy                           0.96      2468\n",
      "   macro avg       0.97      0.96      0.96      2468\n",
      "weighted avg       0.97      0.96      0.96      2468\n",
      " \n",
      "\n",
      "Confusion matrix of svm\n",
      "\n",
      "\n",
      " [[772  32   0]\n",
      " [ 27 794   0]\n",
      " [ 10  18 815]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of svm=\", accuracy_score(y_test,svm_pred),\"\\n\")\n",
    "print(\"Classification of  svm\\n\\n\",classification_report(y_test,svm_pred),\"\\n\")\n",
    "print(\"Confusion matrix of svm\\n\\n\\n\",confusion_matrix(y_test,svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of knn= 0.68354943273906 \n",
      "\n",
      "Classification of  knn\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.66      0.96      0.78       804\n",
      "     Neutral       0.68      0.99      0.81       821\n",
      "     Postive       1.00      0.12      0.21       843\n",
      "\n",
      "    accuracy                           0.68      2468\n",
      "   macro avg       0.78      0.69      0.60      2468\n",
      "weighted avg       0.78      0.68      0.60      2468\n",
      " \n",
      "\n",
      "Confusion matrix of knn\n",
      "\n",
      "\n",
      " [[773  31   0]\n",
      " [  7 814   0]\n",
      " [389 354 100]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of knn=\", accuracy_score(y_test,knn_pred),\"\\n\")\n",
    "print(\"Classification of  knn\\n\\n\",classification_report(y_test,knn_pred),\"\\n\")\n",
    "print(\"Confusion matrix of knn\\n\\n\\n\",confusion_matrix(y_test,knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0005, penalty='l1')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per = Perceptron(penalty = 'l1',\n",
    "                alpha = 0.0005)\n",
    "per.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_pred = per.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  Perceptron= 0.8877633711507293 \n",
      "\n",
      "Classification of   Perceptron\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.82      0.87       804\n",
      "     Neutral       0.83      0.92      0.87       821\n",
      "     Postive       0.93      0.91      0.92       843\n",
      "\n",
      "    accuracy                           0.89      2468\n",
      "   macro avg       0.89      0.89      0.89      2468\n",
      "weighted avg       0.89      0.89      0.89      2468\n",
      " \n",
      "\n",
      "Confusion matrix of  Perceptron\n",
      "\n",
      "\n",
      " [[663 114  27]\n",
      " [ 32 757  32]\n",
      " [ 31  41 771]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of  Perceptron=\", accuracy_score(y_test,per_pred),\"\\n\")\n",
    "print(\"Classification of   Perceptron\\n\\n\",classification_report(y_test,per_pred),\"\\n\")\n",
    "print(\"Confusion matrix of  Perceptron\\n\\n\\n\",confusion_matrix(y_test,per_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = PassiveAggressiveClassifier(class_weight = 'balanced',\n",
    "                                 C = 0.4)\n",
    "pac.fit(x_train,y_train)\n",
    "pac_pred = pac.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  PassiveAggressiveClassifier= 0.9521880064829822 \n",
      "\n",
      "Classification of   PassiveAggressiveClassifier\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.98      0.90      0.94       804\n",
      "     Neutral       0.89      0.98      0.94       821\n",
      "     Postive       1.00      0.97      0.98       843\n",
      "\n",
      "    accuracy                           0.95      2468\n",
      "   macro avg       0.96      0.95      0.95      2468\n",
      "weighted avg       0.96      0.95      0.95      2468\n",
      " \n",
      "\n",
      "Confusion matrix of  PassiveAggressiveClassifier\n",
      "\n",
      "\n",
      " [[725  77   2]\n",
      " [ 11 808   2]\n",
      " [  6  20 817]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of  PassiveAggressiveClassifier=\", accuracy_score(y_test,pac_pred),\"\\n\")\n",
    "print(\"Classification of   PassiveAggressiveClassifier\\n\\n\",classification_report(y_test,pac_pred),\"\\n\")\n",
    "print(\"Confusion matrix of  PassiveAggressiveClassifier\\n\\n\\n\",confusion_matrix(y_test,pac_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_pred = lda.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  LinearDiscriminantAnalysi= 0.9100486223662885 \n",
      "\n",
      "Classification of   LinearDiscriminantAnalysi\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.92      0.90      0.91       804\n",
      "     Neutral       0.83      0.98      0.90       821\n",
      "     Postive       1.00      0.85      0.92       843\n",
      "\n",
      "    accuracy                           0.91      2468\n",
      "   macro avg       0.92      0.91      0.91      2468\n",
      "weighted avg       0.92      0.91      0.91      2468\n",
      " \n",
      "\n",
      "Confusion matrix of  LinearDiscriminantAnalysi\n",
      "\n",
      "\n",
      " [[720  84   0]\n",
      " [ 14 807   0]\n",
      " [ 48  76 719]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of  LinearDiscriminantAnalysi=\", accuracy_score(y_test,lda_pred),\"\\n\")\n",
    "print(\"Classification of   LinearDiscriminantAnalysi\\n\\n\",classification_report(y_test,lda_pred),\"\\n\")\n",
    "print(\"Confusion matrix of  LinearDiscriminantAnalysi\\n\\n\\n\",confusion_matrix(y_test,lda_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIDGE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier()"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc = RidgeClassifier()\n",
    "rc.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_pred = rc.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  ridge= 0.9100486223662885 \n",
      "\n",
      "Classification of   ridge\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.92      0.90      0.91       804\n",
      "     Neutral       0.83      0.98      0.90       821\n",
      "     Postive       1.00      0.85      0.92       843\n",
      "\n",
      "    accuracy                           0.91      2468\n",
      "   macro avg       0.92      0.91      0.91      2468\n",
      "weighted avg       0.92      0.91      0.91      2468\n",
      " \n",
      "\n",
      "Confusion matrix of  ridge\n",
      "\n",
      "\n",
      " [[720  84   0]\n",
      " [ 14 807   0]\n",
      " [ 48  76 719]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of  ridge=\", accuracy_score(y_test,lda_pred),\"\\n\")\n",
    "print(\"Classification of   ridge\\n\\n\",classification_report(y_test,lda_pred),\"\\n\")\n",
    "print(\"Confusion matrix of  ridge\\n\\n\\n\",confusion_matrix(y_test,lda_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random forest classifier= 0.9809562398703403 \n",
      "\n",
      "Accuracy of Multinomial Naive Bayes= 0.8379254457050244 \n",
      "\n",
      "Accuracy of SGD= 0.9448946515397083 \n",
      "\n",
      "Accuracy of Logistic Regression= 0.9529983792544571 \n",
      "\n",
      "Accuracy of svm= 0.9647487844408428 \n",
      "\n",
      "Accuracy of ada = 0.8654781199351702 \n",
      "\n",
      "Accuracy of XGB = 0.784035656401945 \n",
      "\n",
      "Accuracy of OneVsRestClassifier using xgb= 0.9675850891410048 \n",
      "\n",
      "Accuracy of knn= 0.68354943273906 \n",
      "\n",
      "Accuracy of Perceptron= 0.8387358184764991 \n",
      "\n",
      "Accuracy of PassiveAggressiveClassifier= 0.9521880064829822 \n",
      "\n",
      "Accuracy of LinearDiscriminantAnalysi= 0.9100486223662885 \n",
      "\n",
      "Accuracy of ridge= 0.9100486223662885 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Random forest classifier=\", accuracy_score(y_test,rf_pred),'\\n')\n",
    "print(\"Accuracy of Multinomial Naive Bayes=\", accuracy_score(y_test,mn_pred),'\\n')\n",
    "print(\"Accuracy of SGD=\", accuracy_score(y_test,sgd_pred),'\\n')\n",
    "print(\"Accuracy of Logistic Regression=\", accuracy_score(y_test,LR_pred),'\\n')\n",
    "print(\"Accuracy of svm=\", accuracy_score(y_test,svm_pred),\"\\n\")\n",
    "print(\"Accuracy of ada =\", accuracy_score(y_test,ada_pred),\"\\n\")\n",
    "print(\"Accuracy of XGB =\", accuracy_score(y_test,xgb_pred),\"\\n\")\n",
    "print(\"Accuracy of OneVsRestClassifier using xgb=\", accuracy_score(y_test,ovr_model_pred),\"\\n\")\n",
    "print(\"Accuracy of knn=\", accuracy_score(y_test,knn_pred),\"\\n\")\n",
    "print(\"Accuracy of Perceptron=\", accuracy_score(y_test,per_pred),\"\\n\")\n",
    "print(\"Accuracy of PassiveAggressiveClassifier=\", accuracy_score(y_test,pac_pred),\"\\n\")\n",
    "print(\"Accuracy of LinearDiscriminantAnalysi=\", accuracy_score(y_test,lda_pred),\"\\n\")\n",
    "print(\"Accuracy of ridge=\", accuracy_score(y_test,lda_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finally random forest classifier is the best model to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
